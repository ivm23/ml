{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import *\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('netflixSorted.csv', sep=',')\n",
    "\n",
    "dataset = dataset.drop(['Previous Movie', 'Date'],axis = 1)\n",
    "YY = dataset['Rate'].values\n",
    "XX = dataset.drop(['Rate'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = OneHotEncoder(sparse=True).fit_transform(XX.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumOfDiff(A, B):\n",
    "\tu = 0\n",
    "\tsum = 0\n",
    "\tfor i in A:\n",
    "\t\tsum = sum + (i - B[u])**2\n",
    "\t\tu = u + 1\n",
    "\treturn sum\n",
    "\n",
    "def getErr(Y, y_pred, N):\n",
    "\tsum_data2 = sumOfDiff(Y, y_pred)\n",
    "\treturn np.sqrt(sum_data2 / N)\n",
    "\t#r2 =  1 - sum_data2/sum([data**2 for data in(Y - Y.mean())])\n",
    "\n",
    "\t#return float(rmse), float(r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Факторизационная машину 2-го порядка с квадратичной функцией потерь (аналогично линейной регрессии)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class factorization_machine:\n",
    "\n",
    "    def get_batches(self, dataset, batch_size):\n",
    "        X, Y = dataset\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        # Shuffle at the start of epoch\n",
    "        indices = np.arange(n_samples)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        for start in range(0, n_samples, batch_size):\n",
    "            end = min(start + batch_size, n_samples)\n",
    "            batch_idx = indices[start:end]\n",
    "\n",
    "            yield X[batch_idx], Y[batch_idx]\n",
    "            \n",
    "    def prediction(self, X, W, V,X2,X_V, n):\n",
    "        tmp =np.sum(X_V**2-(X2).dot(V**2), axis = 1, keepdims=True)\n",
    "        return X.dot(W.reshape(n,1)) + np.multiply(1/2, tmp )\n",
    "    \n",
    "    def cost(self, curr, pred):\n",
    "        return np.subtract(pred, curr.reshape(len(curr),1))\n",
    "\n",
    "    def step(self, cost, x, n, W, learning_rate):\n",
    "        return W.reshape(n,1) - np.multiply(learning_rate, (x.T).dot(cost))\n",
    "    \n",
    "    def fit(self, X, Y, W, V, learning_rate):\n",
    "                X2 = X.power(2)\n",
    "                X_V = X.dot(V)\n",
    "                \n",
    "                y_pred = prediction(X, W, V, X2, X_V, XX.shape[1])\n",
    "                loss = cost(Y, y_pred)\n",
    "\n",
    "                W = step(loss, X,XX.shape[1] , W, learning_rate)\n",
    "                loss = np.multiply(learning_rate, loss)\n",
    "                \n",
    "                for j in range(k):\n",
    "                    gradV = X.multiply(X_V[:, j].reshape(-1, 1)) - X2.multiply(V[:, j])\n",
    "                    V[:,j] = V[:,j] - loss.reshape(-1) @ gradV\n",
    "                    \n",
    "                return W, V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроссвалидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(kk):\n",
    "    kf = KFold(n_splits=3) \n",
    "    kf.get_n_splits(XX) \n",
    "    \n",
    "    data = pd.DataFrame(columns=[\"T1\", \"T2\", \"T3\",  \"E\", \"STD\"])\n",
    "    \n",
    "    count = 0\n",
    "    for train_i, test_i in kf.split(XX):\n",
    "        print(count)\n",
    "        print('begin')\n",
    "        \n",
    "        factorizationMachine = factorization_machine()\n",
    "        \n",
    "        X_train, X_test = XX[train_i], XX[test_i]\n",
    "        Y_train, Y_test = YY[train_i], YY[test_i]\n",
    "        \n",
    "        n = XX.shape[1]\n",
    "        W0 = 0\n",
    "        W = np.random.random(n)\n",
    "        V = np.random.random((n, k))\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            print(i)\n",
    "            for x_batch, y_batch in factorizationMachine.get_batches((X_train, Y_train), batch_size):\n",
    "                learning_rate = kk /((np.sqrt(i + 1))*x_batch.shape[0])\n",
    "                W,V = factorizationMachine.fit(x_batch, y_batch, W, V, learning_rate)\n",
    "                \n",
    "               \n",
    "        X2 = X_train.power(2)\n",
    "        X_V = X_train.dot(V)\n",
    "        y_pred = factorizationMachine.prediction(X_train, W, V, X2,X_V,n).reshape(-1)\n",
    "        rmse_train = getErr(Y_train, y_pred, len(Y_train))\n",
    "        print (rmse_train)\n",
    "        \n",
    "        X2 = X_test.power(2)\n",
    "        X_V = X_test.dot(V)\n",
    "        y_pred = factorizationMachine.prediction(X_test, W, V,X2, X_V,n).reshape(-1)\n",
    "        rmse_test = getErr(Y_test, y_pred, len(Y_test))\n",
    "        print (rmse_test)\n",
    "        \n",
    "        count = count + 1\n",
    "        data[\"T\" + str(count)] = [ rmse_test, rmse_train] \n",
    "        data[\"E\"] = data[[\"T1\", \"T2\", \"T3\"]].mean(axis=1)\n",
    "        data[\"STD\"] = data[[\"T1\", \"T2\", \"T3\"]].std(axis=1)\n",
    "        print('end')\n",
    "        \n",
    "        \n",
    "    data.index = [\"RMSE_test\", \"RMSE_train\"]     \n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "begin\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0.9654084885451145\n",
      "1.0384698451695498\n",
      "end\n",
      "1\n",
      "begin\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0.9781451498958771\n",
      "0.9989821254404299\n",
      "end\n",
      "2\n",
      "begin\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0.9525943769699476\n",
      "1.1229277419311903\n",
      "end\n",
      "                  T1        T2        T3         E       STD\n",
      "RMSE_test   1.038470  0.998982  1.122928  1.053460  0.063318\n",
      "RMSE_train  0.965408  0.978145  0.952594  0.965383  0.012775\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "epochs = 5\n",
    "batch_size = 1000\n",
    "\n",
    "cross_validation(1.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'scipy.sparse.data' from 'C:\\\\Users\\\\ivm\\\\Anaconda3\\\\lib\\\\site-packages\\\\scipy\\\\sparse\\\\data.py'>\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
